{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9107473",
   "metadata": {},
   "source": [
    "# Cleaning, Preprocessing, and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0feddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking documents: 100%|██████████| 64/64 [00:00<00:00, 1337.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunked data saved to Data/chunks.json with 161 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "INPUT_FILE = \"data.json\"\n",
    "OUTPUT_FILE = \"Data/chunks.json\"\n",
    "CHUNK_SIZE = 300  # Number of words per chunk\n",
    "\n",
    "# Clean and chunk text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def chunk_text(text, size=CHUNK_SIZE):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "# Load JSON input\n",
    "chunks = []\n",
    "\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for row in tqdm(data, desc=\"Chunking documents\"):\n",
    "    content = clean_text(row.get(\"content\", \"\"))\n",
    "    title = row.get(\"title\", \"\")\n",
    "    url = row.get(\"url\", \"\")\n",
    "\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    content_chunks = chunk_text(content)\n",
    "    for idx, chunk in enumerate(content_chunks):\n",
    "        chunks.append({\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"chunk_id\": idx,\n",
    "            \"content\": chunk\n",
    "        })\n",
    "\n",
    "# Save output\n",
    "os.makedirs(Path(OUTPUT_FILE).parent, exist_ok=True)\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Chunked data saved to {OUTPUT_FILE} with {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ec4b6",
   "metadata": {},
   "source": [
    "# Embedding chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0280d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seife\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\seife\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\seife\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [00:05<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalized embeddings saved for cosine similarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# === Step 1: Load your JSON file ===\n",
    "with open('Data/chunks.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "chunks = [item['content'] for item in data if 'content' in item]\n",
    "\n",
    "# === Step 2: Load embedding model ===\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# === Step 3: Generate embeddings ===\n",
    "embeddings = model.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "# === Step 4: Normalize embeddings to unit length (L2 norm = 1)\n",
    "embeddings = normalize(embeddings, norm='l2')  # Now cosine similarity = inner product\n",
    "\n",
    "# === Step 5: Save embeddings and chunks ===\n",
    "with open('Data/embedded_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump({'chunks': chunks, 'embeddings': embeddings}, f)\n",
    "\n",
    "print(\"✅ Normalized embeddings saved for cosine similarity.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2fabc",
   "metadata": {},
   "source": [
    "# Vectore Storing \"FAISS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03242c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS cosine similarity index and chunks saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# === Step 1: Load normalized embeddings and chunks ===\n",
    "with open('Data/embedded_chunks.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "chunks = data['chunks']\n",
    "embeddings = np.array(data['embeddings']).astype('float32')\n",
    "\n",
    "# === Step 2: Create FAISS index using Inner Product (cosine similarity)\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)  # Inner Product = cosine if normalized\n",
    "index.add(embeddings)\n",
    "\n",
    "# === Step 3: Save FAISS index and chunks ===\n",
    "faiss.write_index(index, 'Data/index.faiss')\n",
    "\n",
    "with open('Data/chunks_only.pkl', 'wb') as f:\n",
    "    pickle.dump(chunks, f)\n",
    "\n",
    "print(\"✅ FAISS cosine similarity index and chunks saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef31b7",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a962778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "import google.generativeai as genai\n",
    "\n",
    "# === Step 1: Load FAISS index and chunks ===\n",
    "index = faiss.read_index('Data/index.faiss')\n",
    "\n",
    "with open('Data/chunks_only.pkl', 'rb') as f:\n",
    "    chunks = pickle.load(f)\n",
    "\n",
    "# === Step 2: Load embedding model ===\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# === Step 3: Set up Gemini API ===\n",
    "genai.configure(api_key=\"GEMENI_API_KEY\")\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# === Step 4: Define search function ===\n",
    "def get_relevant_chunks(query, top_k=3):\n",
    "    query_vec = embedder.encode([query])\n",
    "    query_vec = normalize(query_vec, norm='l2').astype('float32')  # normalize query too\n",
    "\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    retrieved_chunks = [chunks[i] for i in I[0]]\n",
    "\n",
    "    print(\"\\n🔍 Top Matching Chunks:\")\n",
    "    for idx, chunk in enumerate(retrieved_chunks):\n",
    "        print(f\"\\n--- Chunk {idx+1} ---\\n{chunk[:300]}...\\n\")\n",
    "\n",
    "    return retrieved_chunks\n",
    "\n",
    "# === Step 5: Generate response with Gemini ===\n",
    "def generate_answer_with_gemini(query, context_chunks):\n",
    "    context_text = \"\\n\\n\".join(context_chunks)\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the user's question:\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a273f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Top Matching Chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Mild depression can make you feel low and as though everything is harder to do. Severe depression can lead to feeling hopeless and, in some cases, suicidal. If you re depressed, you re not alone. In England, 3 in every 100 people will experience depression in any given week. Even more – 8 in every 1...\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Having a baby is a huge life event. It’s normal to experience a range of powerful emotions while you’re pregnant and after giving birth: excitement, joy, and anxiety. You may also feel depressed. It’s not a sign of weakness or anything to feel guilty about. With support and treatment, you can get be...\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "your life - but try to stay open to the possibility of change. There are many different types of help available now. A common treatment for depression involves a combination of self-help, talking therapies and medication. The right treatment for you will depend on the type of depression you have and...\n",
      "\n",
      "\n",
      "💬 Final Answer:\n",
      " Depression is a condition that can make you feel low and as though everything is harder to do. In severe cases, it can lead to feeling hopeless and, in some cases, suicidal. It can affect your mind, body, and behavior, and can manifest in various symptoms, including physical ones.\n"
     ]
    }
   ],
   "source": [
    "# === Step 6: Try with a user question ===\n",
    "user_query = \"What is depression?\"\n",
    "\n",
    "retrieved = get_relevant_chunks(user_query)\n",
    "answer = generate_answer_with_gemini(user_query, retrieved)\n",
    "\n",
    "print(\"\\n💬 Final Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6592aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Top Matching Chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "you can look after yourself. Home of Mental Health Awareness Week...\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "your mental health affects your physical health, and what you can do to help yourself. Home of Mental Health Awareness Week...\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "keeping a diary of your voices. You could note what they say, how they make you feel and how you manage them. This may help you to notice patterns of what makes you feel bad, what makes you feel good, or what triggers your voices. Some people find that standing up to the voices, choosing when to pay...\n",
      "\n",
      "\n",
      "💬 Final Answer:\n",
      " Mental health affects your physical health, and there are things you can do to help yourself. For example, if you experience voices, keeping a diary of them can help you identify patterns and triggers. Some people find it helpful to stand up to the voices, choosing when to pay attention and focusing on more positive ones. Talking therapy can be beneficial, as can keeping busy with hobbies, creative activities, or listening to music.\n"
     ]
    }
   ],
   "source": [
    "# === Step 6: Try with a user question ===\n",
    "user_query = \"Talk to me about mental health.\"\n",
    "\n",
    "retrieved = get_relevant_chunks(user_query)\n",
    "answer = generate_answer_with_gemini(user_query, retrieved)\n",
    "\n",
    "print(\"\\n💬 Final Answer:\\n\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
